
### IDEA
 一般的な楽曲には、コード進行があり、その進行や構成するコードの種類によって、楽曲が人に与える感覚が異なると一般に知られている。
 また、現在AIを用いた楽曲の自動生成の方法が多数提案されているが、まとまりのなさやそれを担保するためにユーザが曲を通してこの部分はこんなふうに生成せよと部分部分で指定しなければならない、感情表現の欠如などの問題がある。
 一方、古典的な楽曲生成では、コードの進行を乱数とコードの進行ルールに則りコード進行を生成して楽曲を作るといった手法が見られていた。こちらでは、一般的なコード進行に則っているため不自然さは少ないが、入力の乱数を工夫しても、楽曲の多様さに限度があった。

　そこで、コードにはドミナントやトニックなどと名付けられるように音の調和度合で分類されている。これは、人間の感覚によるものであるため、明確な基準はないが、安定であると言われるコードには一定の類似性があるはずである。
　一般に公開されている楽曲のコード進行は、歌詞などの要素もあるが、安定→不安定→安定のように波がある。そこで、楽曲の安定さと不安定さを自動的に数値化することで、楽曲のコード進行を数値化でき、これを用いれば、逆にこの安定さ不安定さを時系列データから曲を作ることができるはずであり、これは、曲としての不自然さをなくしつつAIで自動的に曲を作れるはずである。



### 課題
　楽曲の不安定さ(Tension)を数値化する。
　ただし、コードには、ルート音・コードの違いがある。(Cメジャーとcマイナーではルート音が同じだが感じ方が違う)
#### 方法
　人間の音の感じ方を表す方法としてメルスペクトラムがある。これは、人間の可聴域を強調したものらしい。(浅識故...)

　コード→メルスペクトラム→セルフアテンションでテンション推定

　#回帰学習 #self-attention

　package
　jupyter notebook
　torch